{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69a8fde-dca7-4e06-ab80-2e718dc6bea2",
   "metadata": {},
   "source": [
    "# text video retrieval engine\n",
    "\n",
    "> [How to Build a Text-Video Retrieval Engine](https://github.com/towhee-io/examples/blob/07b8d446d26f3af371d8f3e8cb4fd91c9c0cd991/video/text_video_retrieval/1_text_video_retrieval_engine.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19146202-71b6-462f-8670-07d65dd94038",
   "metadata": {},
   "source": [
    "## prepare the data\n",
    "\n",
    "`pdm run data_msrvtt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98182d8d-117d-4f6a-8aa3-60f0b8d037a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of all test set is 1000\n",
      "random sample 1000 examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video7579</td>\n",
       "      <td>data/test_1k_compress/video7579.mp4</td>\n",
       "      <td>a girl wearing red top and black trouser is pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video7725</td>\n",
       "      <td>data/test_1k_compress/video7725.mp4</td>\n",
       "      <td>young people sit around the edges of a room cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video9258</td>\n",
       "      <td>data/test_1k_compress/video9258.mp4</td>\n",
       "      <td>a person is using a phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video7365</td>\n",
       "      <td>data/test_1k_compress/video7365.mp4</td>\n",
       "      <td>cartoon people are eating at a restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video8068</td>\n",
       "      <td>data/test_1k_compress/video8068.mp4</td>\n",
       "      <td>a woman on a couch talks to a a man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id                           video_path  \\\n",
       "0  video7579  data/test_1k_compress/video7579.mp4   \n",
       "1  video7725  data/test_1k_compress/video7725.mp4   \n",
       "2  video9258  data/test_1k_compress/video9258.mp4   \n",
       "3  video7365  data/test_1k_compress/video7365.mp4   \n",
       "4  video8068  data/test_1k_compress/video8068.mp4   \n",
       "\n",
       "                                            sentence  \n",
       "0  a girl wearing red top and black trouser is pu...  \n",
       "1  young people sit around the edges of a room cl...  \n",
       "2                          a person is using a phone  \n",
       "3          cartoon people are eating at a restaurant  \n",
       "4                a woman on a couch talks to a a man  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "raw_video_path = DATA_DIR / \"test_1k_compress\"  # 1k test video path.\n",
    "test_csv_path = DATA_DIR / \"MSRVTT_JSFUSION_test.csv\"  # 1k video caption csv.\n",
    "\n",
    "test_sample_csv_path = DATA_DIR / \"MSRVTT_JSFUSION_test_sample.csv\"\n",
    "\n",
    "sample_num = 1000  # you can change this sample_num to be smaller, so that this notebook will be faster.\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "print(\"length of all test set is {}\".format(len(test_df)))\n",
    "sample_df = test_df.sample(sample_num, random_state=42)\n",
    "\n",
    "sample_df[\"video_path\"] = sample_df.apply(\n",
    "    lambda x: os.path.join(raw_video_path, x[\"video_id\"]) + \".mp4\", axis=1\n",
    ")\n",
    "\n",
    "sample_df.to_csv(test_sample_csv_path)\n",
    "print(\"random sample {} examples\".format(sample_num))\n",
    "\n",
    "df = pd.read_csv(test_sample_csv_path)\n",
    "\n",
    "df[[\"video_id\", \"video_path\", \"sentence\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a8d483-05f6-46d7-ae75-71eb37a79305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml-playground/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from towhee import glob\n",
    "\n",
    "\n",
    "def display_gif(video_path_list, text_list):\n",
    "    html = \"\"\n",
    "    for video_path, text in zip(video_path_list, text_list):\n",
    "        html_line = '<img src=\"{}\"> {} <br/>'.format(video_path, text)\n",
    "        html += html_line\n",
    "    return display.HTML(html)\n",
    "\n",
    "\n",
    "def convert_video2gif(video_path, output_gif_path, num_samples=16):\n",
    "    frames = (\n",
    "        glob(video_path)\n",
    "        .video_decode.ffmpeg(\n",
    "            sample_type=\"uniform_temporal_subsample\", args={\"num_samples\": num_samples}\n",
    "        )\n",
    "        .to_list()[0]\n",
    "    )\n",
    "    imgs = [Image.fromarray(frame) for frame in frames]\n",
    "    imgs[0].save(\n",
    "        fp=output_gif_path, format=\"GIF\", append_images=imgs[1:], save_all=True, loop=0\n",
    "    )\n",
    "\n",
    "\n",
    "def display_gifs_from_video(video_path_list, text_list, tmpdirname=\"./tmp_gifs\"):\n",
    "    Path(tmpdirname).mkdir(exist_ok=True)\n",
    "    gif_path_list = []\n",
    "    for video_path in video_path_list:\n",
    "        video_name = str(Path(video_path).name).split(\".\")[0]\n",
    "        gif_path = Path(tmpdirname) / (video_name + \".gif\")\n",
    "        convert_video2gif(video_path, gif_path)\n",
    "        gif_path_list.append(gif_path)\n",
    "    return display_gif(gif_path_list, text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a6f1d-9605-4562-9fc5-086cfabddc63",
   "metadata": {},
   "source": [
    "Take a look at the ground-truth video-text pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e61d76-8c56-4e74-a128-23d676f452fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning the repo: video-decode/ffmpeg... Be patient and waiting printing 'Successfully'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/Users/yifanwu/.towhee/operators/video-decode/ffmpeg/main'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully clone the repo: video-decode/ffmpeg.\n",
      "Collecting av\n",
      "  Downloading av-10.0.0-cp39-cp39-macosx_11_0_arm64.whl (19.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.6/19.6 MB 9.3 MB/s eta 0:00:00\n",
      "Installing collected packages: av\n",
      "Successfully installed av-10.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 21:19:09,749 - 4383294848 - video_decoder.py-video_decoder:131 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "2023-03-06 21:19:09,811 - 4383294848 - video_decoder.py-video_decoder:133 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      " (repeated 15 more times)\n",
      "2023-03-06 21:19:10,283 - 4383294848 - video_decoder.py-video_decoder:131 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "2023-03-06 21:19:10,311 - 4383294848 - video_decoder.py-video_decoder:133 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      " (repeated 15 more times)\n",
      "2023-03-06 21:19:10,658 - 4383294848 - video_decoder.py-video_decoder:131 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "2023-03-06 21:19:10,684 - 4383294848 - video_decoder.py-video_decoder:133 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      " (repeated 15 more times)\n",
      "2023-03-06 21:19:11,018 - 4383294848 - video_decoder.py-video_decoder:131 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "2023-03-06 21:19:11,061 - 4383294848 - video_decoder.py-video_decoder:133 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      " (repeated 15 more times)\n",
      "2023-03-06 21:19:11,619 - 4383294848 - video_decoder.py-video_decoder:131 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "2023-03-06 21:19:11,639 - 4383294848 - video_decoder.py-video_decoder:133 - WARNING: No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      " (repeated 15 more times)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"tmp_gifs/video7579.gif\"> a girl wearing red top and black trouser is putting a sweater on a dog <br/><img src=\"tmp_gifs/video7725.gif\"> young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party <br/><img src=\"tmp_gifs/video9258.gif\"> a person is using a phone <br/><img src=\"tmp_gifs/video7365.gif\"> cartoon people are eating at a restaurant <br/><img src=\"tmp_gifs/video8068.gif\"> a woman on a couch talks to a a man <br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_show_df = sample_df[:5]\n",
    "video_path_list = sample_show_df[\"video_path\"].to_list()\n",
    "text_list = sample_show_df[\"sentence\"].to_list()\n",
    "tmpdirname = \"./tmp_gifs\"\n",
    "display_gifs_from_video(video_path_list, text_list, tmpdirname=tmpdirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07478ba3-429b-4e82-8e10-fff596cdc6a2",
   "metadata": {},
   "source": [
    "## Create a Milvus Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e65b676-d36e-4f0c-900d-5db52525ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import (\n",
    "    Collection,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    FieldSchema,\n",
    "    connections,\n",
    "    utility,\n",
    ")\n",
    "\n",
    "connections.connect(host=\"127.0.0.1\", port=\"19530\")\n",
    "\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "        FieldSchema(\n",
    "            name=\"id\",\n",
    "            dtype=DataType.INT64,\n",
    "            descrition=\"ids\",\n",
    "            is_primary=True,\n",
    "            auto_id=False,\n",
    "        ),\n",
    "        FieldSchema(\n",
    "            name=\"embedding\",\n",
    "            dtype=DataType.FLOAT_VECTOR,\n",
    "            descrition=\"embedding vectors\",\n",
    "            dim=dim,\n",
    "        ),\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description=\"video retrieval\")\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        \"metric_type\": \"L2\",  # IP\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 2048},\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5863be32-ba9c-4757-a5c6-b8df930b2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = create_milvus_collection(\"text_video_retrieval\", 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf60702-4af0-4a8b-9490-60f1e6e098ec",
   "metadata": {},
   "source": [
    "## Text-Video retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23ef47d-4b49-4d20-90c7-25decc69cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/ml-playground/lib/python3.9/site-packages (from ftfy) (0.2.5)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.1.1\n",
      "Collecting regex\n",
      "  Using cached regex-2022.10.31-cp39-cp39-macosx_11_0_arm64.whl (287 kB)\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2022.10.31\n",
      "CPU times: user 3 s, sys: 183 ms, total: 3.18 s\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "from towhee.dc2 import ops, pipe, register\n",
    "from towhee.operator import PyOperator\n",
    "\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    import csv\n",
    "\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield int(line[\"video_id\"][len(\"video\") :]), line[\"video_path\"]\n",
    "\n",
    "\n",
    "dc = (\n",
    "    pipe.input(\"csv_file\")\n",
    "    .flat_map(\"csv_file\", (\"video_id\", \"video_path\"), read_csv)\n",
    "    .map(\n",
    "        \"video_path\",\n",
    "        \"frames\",\n",
    "        ops.video_decode.ffmpeg(\n",
    "            sample_type=\"uniform_temporal_subsample\", args={\"num_samples\": 12}\n",
    "        ),\n",
    "    )\n",
    "    .map(\n",
    "        \"frames\",\n",
    "        \"vec\",\n",
    "        ops.video_text_embedding.clip4clip(model_name=\"clip_vit_b32\", modality=\"video\"),\n",
    "    )\n",
    "    .map(\n",
    "        (\"video_id\", \"vec\"),\n",
    "        (),\n",
    "        ops.ann_insert.milvus_client(\n",
    "            host=\"127.0.0.1\", port=\"19530\", collection_name=\"text_video_retrieval\"\n",
    "        ),\n",
    "    )\n",
    "    .output(\"video_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d882d87-7775-4d36-9827-b8ea4d1fb414",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc(test_sample_csv_path)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49311ec-b84b-4fb5-ac39-f1e77b6c6987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of inserted data is 0.\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of inserted data is {}.\".format(collection.num_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a825444d-f98b-4f68-9547-acdaf8778263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.94 s, sys: 142 ms, total: 3.08 s\n",
      "Wall time: 3.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    import csv\n",
    "\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line[\"video_id\"], line[\"sentence\"]\n",
    "\n",
    "\n",
    "dc_search = (\n",
    "    pipe.input(\"csv_file\")\n",
    "    .flat_map(\"csv_file\", (\"video_id\", \"sentence\"), read_csv)\n",
    "    .map(\n",
    "        \"sentence\",\n",
    "        \"vec\",\n",
    "        ops.video_text_embedding.clip4clip(model_name=\"clip_vit_b32\", modality=\"text\"),\n",
    "    )\n",
    "    .map(\n",
    "        \"vec\",\n",
    "        \"top10_raw_res\",\n",
    "        ops.ann_search.milvus_client(\n",
    "            host=\"127.0.0.1\",\n",
    "            port=\"19530\",\n",
    "            collection_name=\"text_video_retrieval\",\n",
    "            limit=10,\n",
    "        ),\n",
    "    )\n",
    "    .map(\"top10_raw_res\", (\"top1\", \"top5\", \"top10\"), lambda x: (x[:1], x[:5], x[:10]))\n",
    "    .map(\"video_id\", \"ground_truth\", lambda x: x[len(\"video\") :])\n",
    "    .output(\"video_id\", \"sentence\", \"ground_truth\", \"top1\", \"top5\", \"top10\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2410dc2-1633-4e27-a791-34d868afb375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">video_id</th> <th style=\"text-align: center; font-size: 130%; border: none;\">sentence</th> <th style=\"text-align: center; font-size: 130%; border: none;\">ground_truth</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top1</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10</th></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7579</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a girl wearing red top and black trouser is putting a sweater on a dog</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">7579</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.4151520729064941]] len=1</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.4151520729064941],[9969, 1.4799103736877441],[8837, 1.4897732734680176],[9347, 1.4948582649230957],...] len=5</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7579, 1.4151520729064941],[9969, 1.4799103736877441],[8837, 1.4897732734680176],[9347, 1.4948582649230957],...] len=10</td></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7725</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">young people sit around the edges of a room clapping and raising their arms while others dance in the center during a party</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">7725</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3622068166732788]] len=1</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3622068166732788],[8014, 1.4865269660949707],[8339, 1.4922082424163818],[8442, 1.5024113655090332],...] len=5</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7725, 1.3622068166732788],[8014, 1.4865269660949707],[8339, 1.4922082424163818],[8442, 1.5024113655090332],...] len=10</td></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video9258</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a person is using a phone</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">9258</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9258, 1.401197075843811]] len=1</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9258, 1.401197075843811],[9257, 1.4228630065917969],[9697, 1.4413856267929077],[7910, 1.4945622682571411],...] len=5</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[9258, 1.401197075843811],[9257, 1.4228630065917969],[9697, 1.4413856267929077],[7910, 1.4945622682571411],...] len=10</td></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video7365</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">cartoon people are eating at a restaurant</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">7365</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7365, 1.4027700424194336]] len=1</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7365, 1.4027700424194336],[8781, 1.4623045921325684],[9537, 1.4739770889282227],[7831, 1.505112886428833],...] len=5</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7365, 1.4027700424194336],[8781, 1.4623045921325684],[9537, 1.4739770889282227],[7831, 1.505112886428833],...] len=10</td></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">video8068</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">a woman on a couch talks to a a man</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">8068</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7162, 1.471674919128418]] len=1</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7162, 1.471674919128418],[8304, 1.4787474870681763],[8068, 1.4926886558532715],[7724, 1.4982554912567139],...] len=5</td> <td style=\"text-align: left; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">[[7162, 1.471674919128418],[8304, 1.4787474870681763],[8068, 1.4926886558532715],[7724, 1.4982554912567139],...] len=10</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from towhee.dc2 import DataCollection\n",
    "\n",
    "ret = DataCollection(dc_search(test_sample_csv_path))\n",
    "ret.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b4eb7-1033-4e61-8bf0-cf524d651f90",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "`Recall@topk` is the proportion of relevant items found in the top-k recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c82f185-b9b1-42b0-ab74-f93eced02d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">top1_mean_hit_ratio</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top5_mean_hit_ratio</th> <th style=\"text-align: center; font-size: 130%; border: none;\">top10_mean_hit_ratio</th></tr> <tr><td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.426</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.716</td> <td style=\"text-align: center; vertical-align: center; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.814</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_hit_ratio(actual, *predicteds):\n",
    "    rets = []\n",
    "    for predicted in predicteds:\n",
    "        ratios = []\n",
    "        for act, pre in zip(actual, predicted):\n",
    "            hit_num = len(set(act) & set(pre))\n",
    "            ratios.append(hit_num / len(act))\n",
    "        rets.append(sum(ratios) / len(ratios))\n",
    "    return rets\n",
    "\n",
    "\n",
    "def get_label_from_raw_data(data):\n",
    "    ret = []\n",
    "    for item in data:\n",
    "        ret.append(item[0])\n",
    "    return ret\n",
    "\n",
    "\n",
    "ev = (\n",
    "    pipe.input(\"dc_data\")\n",
    "    .flat_map(\"dc_data\", \"data\", lambda x: x)\n",
    "    .map(\n",
    "        \"data\",\n",
    "        (\"ground_truth\", \"top1\", \"top5\", \"top10\"),\n",
    "        lambda x: (\n",
    "            [int(x.ground_truth)],\n",
    "            get_label_from_raw_data(x.top1),\n",
    "            get_label_from_raw_data(x.top5),\n",
    "            get_label_from_raw_data(x.top10),\n",
    "        ),\n",
    "    )\n",
    "    .window_all(\n",
    "        (\"ground_truth\", \"top1\", \"top5\", \"top10\"),\n",
    "        (\"top1_mean_hit_ratio\", \"top5_mean_hit_ratio\", \"top10_mean_hit_ratio\"),\n",
    "        mean_hit_ratio,\n",
    "    )\n",
    "    .output(\"top1_mean_hit_ratio\", \"top5_mean_hit_ratio\", \"top10_mean_hit_ratio\")\n",
    ")\n",
    "\n",
    "DataCollection(ev(ret)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e57429-21da-4d0c-8ed3-277aaeda3b10",
   "metadata": {},
   "source": [
    "## Release a Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3132d0-c23c-41de-b1c2-c6b49bf76536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio\n",
    "\n",
    "show_num = 3\n",
    "\n",
    "milvus_search_pipe = (\n",
    "    pipe.input(\"sentence\")\n",
    "    .map(\n",
    "        \"sentence\",\n",
    "        \"vec\",\n",
    "        ops.video_text_embedding.clip4clip(\n",
    "            model_name=\"clip_vit_b32\", modality=\"text\", device=\"cpu\"\n",
    "        ),\n",
    "    )\n",
    "    .map(\n",
    "        \"vec\",\n",
    "        \"rows\",\n",
    "        ops.ann_search.milvus_client(\n",
    "            host=\"127.0.0.1\",\n",
    "            port=\"19530\",\n",
    "            collection_name=\"text_video_retrieval\",\n",
    "            limit=show_num,\n",
    "        ),\n",
    "    )\n",
    "    .map(\n",
    "        \"rows\",\n",
    "        \"videos_path\",\n",
    "        lambda rows: (\n",
    "            os.path.join(raw_video_path, \"video\" + str(r[0]) + \".mp4\") for r in rows\n",
    "        ),\n",
    "    )\n",
    "    .output(\"videos_path\")\n",
    ")\n",
    "\n",
    "\n",
    "def milvus_search_function(text):\n",
    "    return milvus_search_pipe(text).to_list()[0][0]\n",
    "\n",
    "\n",
    "# print(milvus_search_function('a girl wearing red top and black trouser is putting a sweater on a dog'))\n",
    "\n",
    "\n",
    "interface = gradio.Interface(\n",
    "    milvus_search_function,\n",
    "    inputs=[gradio.Textbox()],\n",
    "    outputs=[gradio.Video(format=\"mp4\") for _ in range(show_num)],\n",
    ")\n",
    "\n",
    "interface.launch(inline=True, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f249b1-92e2-400d-bc32-28ab090a3bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
